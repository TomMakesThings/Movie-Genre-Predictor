{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://avatars.githubusercontent.com/u/61354833\" align=\"left\" width=\"70\" height=\"70\">\n",
    "\n",
    "Code by [TomMakesThings](https://tommakesthings.github.io/Movie-Genre-Predictor/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **About**\n",
    "This code was written by myself, but forms part of a group coursework. The aim of the project being to create a multi-label classifier that can predict the genre of film descriptions from IMDb. To find out more, visit https://tommakesthings.github.io/Movie-Genre-Predictor/.\n",
    "\n",
    "This notebook was created to test loading an LSTM classifer and text pre-processor from file before deployment of the model onto the web application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook has been developed using Python 3.8.5 and <a href=\"https://www.anaconda.com/\">Anaconda3</a> with conda 4.10.1. If you would like to recreate the environment, the YAML file environment.yml can be found on <a href=\"https://github.com/TomMakesThings/Movie-Genre-Predictor/blob/main/environment.yml\">GitHub</a>. Using this, it is possible to recreate the environment using the command `conda env create -f environment.yml` through the Anaconda terminal. For more detail refer to the <a href=\"https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#activating-an-environment\">conda docs</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import spacy\n",
    "import pickle\n",
    "import dill\n",
    "import unicodedata\n",
    "import re\n",
    "from torchtext.legacy import data\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class for the LSTM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilmClassifierLSTM(nn.Module):\n",
    "    \"\"\" \n",
    "    Long-short term memory (LSTM) classifier\n",
    "    Layers: Embedding -> LSTM -> fully connected\n",
    "    \n",
    "    Parameters:\n",
    "        n_vocab: Number of words TEXT Field was trained on\n",
    "        n_classes: Number of genres\n",
    "        pad_index: Index of <pad> token\n",
    "        unk_index: Index of <unk> token\n",
    "        n_embedding: Size of the trained vectors, e.g if using 'glove.6B.100d', set to 100\n",
    "        pretrained_embeddings: Vectors from pre-trained word embedding such as GloVe\n",
    "        n_hidden: Number of hidden layers\n",
    "        dropout: Dropout rate, e.g 0.2 = 20% dropout\n",
    "        activation: Set as \"softmax\" or \"sigmoid\"\n",
    "        bidirectiona: Whether to use bidirectional LSTM\n",
    "        batch_norm: Whether to apply a batch normalization layer\n",
    "    \n",
    "    Return on forward pass:\n",
    "        output: Predicted probabilities for each class\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_vocab, n_classes, pad_index, unk_index, n_embedding, pretrained_embeddings=None,\n",
    "                 n_hidden=256, dropout=0.2, activation=\"sigmoid\", bidirectional=True, batch_norm=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bidirectional = bidirectional\n",
    "        self.batch_norm = batch_norm\n",
    "        \n",
    "        if bidirectional:\n",
    "            # Use two layers for bidirectionality\n",
    "            n_layers = 2\n",
    "            # Double size of linear output\n",
    "            linear_hidden = n_hidden * 2\n",
    "        else:\n",
    "            n_layers = 1\n",
    "            linear_hidden = n_hidden\n",
    "        \n",
    "        # Create model layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.embedding = nn.Embedding(n_vocab, n_embedding, padding_idx=pad_index) # Tell embedding not to learn <pad> embeddings\n",
    "        self.lstm = nn.LSTM(n_embedding, n_hidden, num_layers=n_layers, dropout=dropout, bidirectional=bidirectional)\n",
    "        self.batchnorm = nn.BatchNorm1d(linear_hidden)\n",
    "        self.linear = nn.Linear(linear_hidden, n_classes)\n",
    "        \n",
    "        # Set output activation function\n",
    "        if activation == \"softmax\":\n",
    "            self.activation = nn.Softmax(dim=1)\n",
    "        else:\n",
    "            # Sigmoid recommended for multi-label\n",
    "            self.activation = nn.Sigmoid()\n",
    "        \n",
    "        if pretrained_embeddings != None:\n",
    "            # Replace weights of embedding layer\n",
    "            self.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "            # Set padding and unknown tokens to zero\n",
    "            self.embedding.weight.data[pad_index] = torch.zeros(n_embedding)\n",
    "            self.embedding.weight.data[unk_index] = torch.zeros(n_embedding)\n",
    "\n",
    "    def forward(self, text, text_lengths):\n",
    "        # Create word embedding, then apply drop out\n",
    "        embedded = self.embedding(text)\n",
    "        dropped_embedded = self.dropout(embedded)\n",
    "        # Pack the embedding so that LSTM only processes non-embedded sequences\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(dropped_embedded, text_lengths.to('cpu'))\n",
    "        # Return output of all hidden states in the sequence, hidden state of the last LSTM unit and cell state\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
    "        # Unpack packed_output\n",
    "        unpacked_output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            # Find the final two hidden states and join them together\n",
    "            top_two_hidden = torch.cat((hidden[-1], hidden[-2]), dim=1)\n",
    "            if self.batch_norm:\n",
    "                top_two_hidden = self.batchnorm(top_two_hidden)\n",
    "            # Apply dropout, pass through fully connected layer, then apply activation function\n",
    "            output = self.activation(self.linear(self.dropout(top_two_hidden)))\n",
    "        else:\n",
    "            # Apply dropout to final hidden state, pass through fully connected layer, then apply activation function\n",
    "            output = self.activation(self.linear(self.dropout(hidden[-1])))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DescriptionTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Process the movie descriptions before classification\n",
    "    \n",
    "    Parameters:\n",
    "        stop_words: The stop word list\n",
    "        transformation: Lemmatization or stemming\n",
    "        contractions: Set as True to contract words\n",
    "        stemmer_algorithm: Algorithm to use when applying stemming, defaults to Porter if not given\n",
    "        verbose: set as 0 to print nothing, 1 to print progress and 2 to print progress and data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, stop_words, transformation=\"lemmatize\", contractions=False, \n",
    "                 stemmer_algorithm=None, verbose=0):\n",
    "        # Settable parameters\n",
    "        self.stop_words = stop_words\n",
    "        self.transformation = transformation\n",
    "        self.contractions = contractions\n",
    "        self.stemmer_algorithm = stemmer_algorithm if stemmer_algorithm else PorterStemmer()\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Other\n",
    "        self.data = None\n",
    "        self.column_name = None\n",
    "        \n",
    "    def fit(self, x):\n",
    "        if self.verbose > 0:\n",
    "            print(colored(\"Called Description Transformer Fit\", color=\"blue\", attrs=['bold', 'underline']))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        if self.verbose > 0:\n",
    "            print(colored(\"Called Description Transformer Transform\", color=\"blue\", attrs=['bold', 'underline']))\n",
    "            print(\"Processing description text\")\n",
    "            \n",
    "        # Copy the data and find the name of the description column\n",
    "        self.data = x.copy()\n",
    "        self.column_name = self.data.columns.values[0]\n",
    "        \n",
    "        # Load spaCy language processorz\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        # Load pre-trained word embedding if using contractions\n",
    "        contraction = Contractions(api_key=\"glove-twitter-25\") if self.contractions else None\n",
    "        \n",
    "        # Process text by iterating over each sample's index and description\n",
    "        for idx, sample in zip(self.data.index.values, self.data.values):\n",
    "            # Change accented characters, e.g Ã  -> a\n",
    "            sample = self.remove_accents(str(sample))\n",
    "            if contraction:\n",
    "                # Contract words, e.g \"hasn't\" -> \"has not\"\n",
    "                sample = list(contraction.expand_texts([sample], precise=True))\n",
    "                sample = ''.join(sample)\n",
    "                \n",
    "            # Input sample text into spaCy language processor\n",
    "            doc = nlp(sample)\n",
    "            # Split sample text into sentences\n",
    "            sentences = list(doc.sents)\n",
    "            \n",
    "            for word_idx in range(len(sentences)):\n",
    "                # Remove punctuation tokens, e.g. ! , .\n",
    "                sentences[word_idx] = [token for token in sentences[word_idx] if not token.is_punct]\n",
    "            \n",
    "                # Remove stop words\n",
    "                if self.stop_words:\n",
    "                    sentences[word_idx] = [token for token in sentences[word_idx] if token.text.lower() not in self.stop_words]\n",
    "            \n",
    "                # Apply lemmatization\n",
    "                if self.transformation[0].lower() == \"l\":\n",
    "                    # Resolve words to their dictionary form using PoS tags\n",
    "                    sentences[word_idx] = [token.lemma_.lower() for token in sentences[word_idx]]\n",
    "                    \n",
    "                # Apply stemming (only if lemmatization not applied)\n",
    "                elif self.transformation[0].lower() == \"s\":\n",
    "                    # Stem tokens\n",
    "                    for char_idx in range(len(sentences[word_idx])):\n",
    "                        # Apply stemmer to each word\n",
    "                        stemmed = self.stemmer_algorithm.stem(sentences[word_idx][char_idx].text)\n",
    "                        # Convert back to type Token and update word in sentence\n",
    "                        sentences[word_idx][char_idx] = nlp(stemmed)[0]\n",
    "                        \n",
    "                # Remove remaining punctuation within tokens, e.g. \"(years)\" -> \"years\", not including -\n",
    "                sentences[word_idx] = [token.translate(str.maketrans('', '', '!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~')) for token in sentences[word_idx]]\n",
    "                \n",
    "            # Split words containing dash or spaces caused by lemmatization, e.g. \"16-year\" -> \"16\" + \"year\"\n",
    "            for k in range(len(sentences)):\n",
    "                new_sentence = []\n",
    "                for token in sentences[k]:\n",
    "                    split_token = re.split(' |-', token)\n",
    "                    for word in split_token:\n",
    "                        # Check word not empty\n",
    "                        if word:\n",
    "                            new_sentence.append(word)\n",
    "                # Replace words in sentence\n",
    "                sentences[k] = new_sentence\n",
    "                    \n",
    "            # Remove empty lists from list of sentences\n",
    "            sentences = [sent for sent in sentences if sent != []]\n",
    "            # The join the sentences and update the descriptions dataframe\n",
    "            word_list = [word for sent in sentences for word in sent]\n",
    "            self.data.loc[idx, self.column_name] = ' '.join([str(elem) for elem in word_list])\n",
    "            \n",
    "        if self.verbose > 1:\n",
    "            display(self.data)\n",
    "        if self.verbose > 0:\n",
    "            print(colored(\"Finshed processing all descriptions\\n\", color=\"blue\", attrs=['bold', 'underline']))\n",
    "            \n",
    "        return self.data\n",
    "    \n",
    "    def remove_accents(self, text):\n",
    "        # Remove accent or unknown characters from text\n",
    "        text = unicodedata.normalize('NFD', text)\\\n",
    "               .encode('ascii', 'ignore')\\\n",
    "               .decode(\"utf-8\")\n",
    "        return str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_genres(text, label_threshold=0.5, model_kwargs_file='model_kwargs.pickle', \n",
    "                   model_weights_file='trained_model.pt', binary_encoder_file='binary_encoder.pickle', \n",
    "                   TEXT_field_file=\"TEXT.Field\", text_preprocessor_file=\"text_preprocessor.pickle\"):\n",
    "\n",
    "     # Load the text preprocessor transformer\n",
    "    text_preprocessor = pickle.load(open(text_preprocessor_file, 'rb'))\n",
    "    # Load the multi-hot binary encoder\n",
    "    binary_encoder = pickle.load(open(binary_encoder_file, 'rb'))\n",
    "    # Load TorchText TEXT field\n",
    "    TEXT = dill.load(open(TEXT_field_file, \"rb\"))\n",
    "    # Load the model parameters\n",
    "    model_kwargs = pickle.load(open(model_kwargs_file, 'rb'))\n",
    "    # Determine device\n",
    "    device = 'cpu'\n",
    "    \n",
    "    # Convert text into dataframe to be compatible\n",
    "    text_df = pd.DataFrame(data=[text], columns=[\"description\"])\n",
    "    # Process the text\n",
    "    text_preprocessor.verbose = 0\n",
    "    processed_text = text_preprocessor.transform(text_df)\n",
    "    # Convert back to string\n",
    "    processed_text = str(processed_text.values[0][0])\n",
    "    \n",
    "    # Get indexes of tokens\n",
    "    token_indexes = [TEXT.vocab.stoi[token] for token in processed_text.split()]\n",
    "    # Convert indexes to tensor\n",
    "    token_tensor = torch.LongTensor(token_indexes).to(device)\n",
    "    # Add extra dimension to shape to replicate batch\n",
    "    token_tensor = token_tensor.unsqueeze(1)\n",
    "    # Get the length of the text\n",
    "    length_tensor = torch.LongTensor([len(token_indexes)])\n",
    "    \n",
    "    # Create the model\n",
    "    model = FilmClassifierLSTM(**model_kwargs)\n",
    "    # Set device\n",
    "    model = model.to(device)\n",
    "    # Load the model weights from file\n",
    "    model.load_state_dict(torch.load(model_weights_file))\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Make a prediction\n",
    "    prediction = model(token_tensor, length_tensor)\n",
    "    # Convert model outputs to binary labels, then to genre\n",
    "    predicted_labels = torch.tensor([[1 if value > label_threshold else 0 for value in sample] for sample in prediction])\n",
    "    if not 1 in predicted_labels:\n",
    "        # Prevent no labels being predicted\n",
    "        best_label = prediction.argmax(1)[0].item()\n",
    "        predicted_labels[0][best_label] = 1\n",
    "        \n",
    "    # Calculate the percentage prediction\n",
    "    predicted_categories_scores = []\n",
    "    for idx in range(len(predicted_labels[0])):\n",
    "        if predicted_labels[0][idx].item() == 1:\n",
    "            predicted_categories_scores.append(prediction[0][idx].item())\n",
    "        \n",
    "    # Fit the encoder so it can be used\n",
    "    binary_encoder.fit(binary_encoder.classes)\n",
    "    # Convert the labels from binary to genres\n",
    "    predicted_categories = binary_encoder.inverse_transform(predicted_labels.cpu())\n",
    "    predicted_categories = list(predicted_categories[0])\n",
    "    \n",
    "    return predicted_categories, predicted_categories_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter an IMDb film / series description and see the predicted genre(s) for the best trained model.\n",
    "For example:\n",
    "* \"The Avengers and their allies must be willing to sacrifice all in an attempt to defeat the powerful Thanos before his blitz of devastation and ruin puts an end to the universe.\"\n",
    "* \"A group of young adults visit a boarded up campsite named Crystal Lake where they soon encounter the mysterious Jason Voorhees and his deadly intentions.\"\n",
    "* \"Comedy following the exploits of Det. Jake Peralta and his diverse, lovable colleagues as they police the NYPD's 99th Precinct.\"\n",
    "* \"While navigating their careers in Los Angeles, a pianist and an actress fall in love while attempting to reconcile their aspirations for the future.\"\n",
    "* \"Early in his crime-solving career, Sherlock Holmes attempts to prevent Moriarty from cornering the heroin market.\"\n",
    "* \"Sheriff Deputy Rick Grimes wakes up from a coma to learn the world is in ruins and must lead a group of survivors to stay alive.\"\n",
    "* \"As a new threat to the galaxy rises, Rey, a desert scavenger, and Finn, an ex-stormtrooper, must join Han Solo and Chewbacca to search for the one hope of restoring peace.\"\n",
    "* \"A young woman, traumatized by a tragic event in her past, seeks out vengeance against those who crossed her path.\"\n",
    "* \"Pack up for a howling fun movie adventure filled with action, laughs, and tender moments as Kate and Humphrey take their pups on their first family vacation!\"\n",
    "* \"Stuck in a time loop, two wedding guests develop a budding romance while living the same day over and over again.\"\n",
    "* \"The brash James T. Kirk tries to live up to his father's legacy with Mr. Spock keeping him in check as a vengeful Romulan from the future creates black holes to destroy the Federation one planet at a time.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Avengers and their allies must be willing to sacrifice all in an attempt to defeat the powerful Thanos before his blitz of devastation and ruin puts an end to the universe.\n",
      "['Action', 'Adventure'] [0.964628279209137, 0.7237955927848816]\n",
      "\n",
      "\n",
      "A group of young adults visit a boarded up campsite named Crystal Lake where they soon encounter the mysterious Jason Voorhees and his deadly intentions.\n",
      "['Horror', 'Thriller'] [0.9791640639305115, 0.6287962794303894]\n",
      "\n",
      "\n",
      "Comedy following the exploits of Det. Jake Peralta and his diverse, lovable colleagues as they police the NYPD's 99th Precinct.\n",
      "['Comedy', 'Crime'] [0.9512444138526917, 0.948302149772644]\n",
      "\n",
      "\n",
      "While navigating their careers in Los Angeles, a pianist and an actress fall in love while attempting to reconcile their aspirations for the future.\n",
      "['Drama', 'Romance'] [0.9372848868370056, 0.8990883231163025]\n",
      "\n",
      "\n",
      "Early in his crime-solving career, Sherlock Holmes attempts to prevent Moriarty from cornering the heroin market.\n",
      "['Crime', 'Mystery'] [0.8682650923728943, 0.8462961316108704]\n",
      "\n",
      "\n",
      "Sheriff Deputy Rick Grimes wakes up from a coma to learn the world is in ruins and must lead a group of survivors to stay alive.\n",
      "['Action', 'Adventure'] [0.7481085658073425, 0.7302215695381165]\n",
      "\n",
      "\n",
      "As a new threat to the galaxy rises, Rey, a desert scavenger, and Finn, an ex-stormtrooper, must join Han Solo and Chewbacca to search for the one hope of restoring peace.\n",
      "['Action', 'Adventure', 'Sci-Fi'] [0.959194004535675, 0.8415076732635498, 0.9190459251403809]\n",
      "\n",
      "\n",
      "A young woman, traumatized by a tragic event in her past, seeks out vengeance against those who crossed her path.\n",
      "['Drama', 'Thriller'] [0.8170848488807678, 0.5107693672180176]\n",
      "\n",
      "\n",
      "Pack up for a howling fun movie adventure filled with action, laughs, and tender moments as Kate and Humphrey take their pups on their first family vacation!\n",
      "['Comedy', 'Family'] [0.9724793434143066, 0.8792732357978821]\n",
      "\n",
      "\n",
      "Stuck in a time loop, two wedding guests develop a budding romance while living the same day over and over again.\n",
      "['Comedy', 'Romance'] [0.8595302700996399, 0.8931884765625]\n",
      "\n",
      "\n",
      "The brash James T. Kirk tries to live up to his father's legacy with Mr. Spock keeping him in check as a vengeful Romulan from the future creates black holes to destroy the Federation one planet at a time.\n",
      "['Adventure', 'Fantasy', 'Sci-Fi'] [0.7590023875236511, 0.5646020174026489, 0.7096937298774719]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descriptions = [\"The Avengers and their allies must be willing to sacrifice all in an attempt to defeat the powerful Thanos before his blitz of devastation and ruin puts an end to the universe.\",\n",
    "                \"A group of young adults visit a boarded up campsite named Crystal Lake where they soon encounter the mysterious Jason Voorhees and his deadly intentions.\",\n",
    "                \"Comedy following the exploits of Det. Jake Peralta and his diverse, lovable colleagues as they police the NYPD's 99th Precinct.\",\n",
    "                \"While navigating their careers in Los Angeles, a pianist and an actress fall in love while attempting to reconcile their aspirations for the future.\",\n",
    "                \"Early in his crime-solving career, Sherlock Holmes attempts to prevent Moriarty from cornering the heroin market.\",\n",
    "                \"Sheriff Deputy Rick Grimes wakes up from a coma to learn the world is in ruins and must lead a group of survivors to stay alive.\",\n",
    "                \"As a new threat to the galaxy rises, Rey, a desert scavenger, and Finn, an ex-stormtrooper, must join Han Solo and Chewbacca to search for the one hope of restoring peace.\",\n",
    "                \"A young woman, traumatized by a tragic event in her past, seeks out vengeance against those who crossed her path.\",\n",
    "                \"Pack up for a howling fun movie adventure filled with action, laughs, and tender moments as Kate and Humphrey take their pups on their first family vacation!\",\n",
    "                \"Stuck in a time loop, two wedding guests develop a budding romance while living the same day over and over again.\",\n",
    "                \"The brash James T. Kirk tries to live up to his father's legacy with Mr. Spock keeping him in check as a vengeful Romulan from the future creates black holes to destroy the Federation one planet at a time.\"]\n",
    "\n",
    "for desc in descriptions:\n",
    "    print(desc)\n",
    "    pred_genres, pred_scores = text_to_genres(desc, label_threshold=0.5, model_kwargs_file='Best_Model/model_kwargs.pickle', \n",
    "                                              model_weights_file='Best_Model/trained_model.pt', binary_encoder_file='Best_Model/binary_encoder.pickle', \n",
    "                                              TEXT_field_file=\"Best_Model/TEXT.Field\", text_preprocessor_file=\"Best_Model/text_preprocessor.pickle\")\n",
    "    print(pred_genres, pred_scores)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
