<!DOCTYPE html>
<html>
<head>
	<meta name="description" content="University final year project on single-cell RNA sequencing">
  <meta name="keywords" content="scRNA-seq, clustering, topological data analysis">
  <meta name="author" content="TomMakesThings">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<!-- Website icon -->
	<link rel="shortcut icon" type="image/x-icon" href="Assets/Icon/favicon.ico">

	<title>IMDb Movie Genre Predictor</title>

	<!-- Links to the CSS stylesheets -->
	<link rel="stylesheet" href="Stylesheets\main.css">
	<link rel="stylesheet" href="Stylesheets\navbar.css">
	<link rel="stylesheet" href="Stylesheets\about.css">
	<link rel="stylesheet" href="Stylesheets\dataset.css">
	<link rel="stylesheet" href="Stylesheets\code.css">
	<link rel="stylesheet" href="Stylesheets\graphs.css">
	<link rel="stylesheet" href="Stylesheets\topicmodelling.css">
	<link rel="stylesheet" href="Stylesheets\footer.css">
</head>

<body>

<div class="header">
	<div id="header-top" onmouseover="profileHover(this);" onmouseout="profileUnhover(this);">
		<div id="header-tom">
			<a href="https://tommakesthings.github.io/" target="_blank"><img src="Assets/Images/Profile.png" alt="GitHub profile picture" class="profilepic" id="tomprofile" onmouseover="profileHover(this);" onmouseout="profileUnhover(this);"></a>
			<a href="https://tommakesthings.github.io/" target="_blank" id="username" class="navtext">TomMakesThings +</a>
			<a href="https://tommakesthings.github.io/" target="_blank"><p id="hint">(click to see more of my work)</p></a>
		</div>
		<div id="header-others">
			<a href="https://github.com/rogerchenrc" target="_blank"><img src="https://avatars.githubusercontent.com/u/56882421?v=4" alt="GitHub profile picture" class="profilepic other-profile"></a>
			<a href="https://github.com/laviniafr" target="_blank"><img src="https://avatars.githubusercontent.com/u/66881011?v=4" alt="GitHub profile picture" class="profilepic other-profile" style="margin-right: 0px;"></a>
		</div>
	</div>
	<div id="header-center">
		<a href="https://github.com/TomMakesThings/Movie-Genre-Predictor" target="_blank" id="sitename" class="navtext">IMDb Movie Genre Predictor</a>
		<a href="https://github.com/TomMakesThings/Movie-Genre-Predictor" target="_blank"><img src="Assets/Images/Clapper.png" alt="Film clapper" id="clapper"></a>
	</div>
	<div class="header-right" id="visible-header">
		<a href="#about" class="navtext">About</a>
		<a href="#data" class="navtext">Data</a>
		<a href="#classifier" class="navtext">Classifier</a>
		<a href="#topicmodelling" class="navtext">Topic Modelling</a>
		<a href="#code" class="navtext">Running the Code</a>
		<a href="#contributions" class="navtext">Contributions</a>
	</div>
</div>

<div class="content">
	<div>
		<a name="about" class="anchor"></a>
  	<h1>About</h1>
		<p>This site explains a natural language processing (NLP) group project done in collaboration with <a href="https://github.com/rogerchenrc" target="_blank">rogerchenrc</a> and <a href="https://github.com/laviniafr" target="_blank">laviniafr</a>.
			In this we tested different NLP techniques and model architectures to create a CI/CD pipeline to train and deploy a multi-label classifier.
			The classifier was trained on dataset of movie descriptions to predict the top fitting genre(s) with 12 possible values including: Drama, Comedy, Action, Crime, Thriller, Romance, Horror, Adventure, Mystery, Family, Fantasy and Sci-Fi.
		 	The state of the best trained model was then saved to file and deployed on a custom built web server as demonstrated in the video below:
		</p>

		<br>

		<video controls>
		  <source src="Assets/Videos/Site-Demo.mov" type="video/mp4">
				Your browser does not support the video tag.
		</video>

	</div>

	<br>

	<div>
		<a name="data" class="anchor"></a>
		<h1>Data</h1>
		<p>We decided to use the <a href="https://www.kaggle.com/stefanoleone992/imdb-extensive-dataset">IMDb movies extensive dataset</a> from Kaggle.
			This contains 84,983 samples providing a sufficient number to train a robust classifier.
			Although each film has many attributes, such as year of release and director, we only required the original title, description and list of genres to use as training labels.
			Some pre-processing was therefore required to remove samples missing this information and to remove unnecessary attributes.
			This lead to 2,115 samples being dropped with 83,740 remaining.
		</p>
		<figure class="dataset centered">
			<p><img class="dataset centered" src="Assets/Images/Dataset.png"></p>
			<figcaption>Figure 1: Random samples from the IMDb movies extensive dataset</figcaption>
		</figure>

		<br>

		<details>
			<summary class="h2">Analysing the Labels and Descriptions</summary>
			<p>All films have between one and three genres, each of which can be used as a label during classification.
				After analysing all samples, it was discovered that there were 25 unique values.
				However, they were not evenly distributed with 26.7% of samples belonging to Drama and eight genres with less than 1%.
			</p>
			<div>
				<div align="center">
					<figure class="centered" id="movies-per-genre">
						<p><img src="Assets/Images/Movies-Per-Genre.png" style="max-width: 900px; width: 100%;"></p>
						<figcaption>Figure 2a: Graph showing the number of samples belonging to each genre</figcaption>
						<br>
					</figure>
					<figure class="centered" id="genres-per-movie" style="display: none;">
						<p><img id="genres-per-movie" src="Assets/Images/Genres-Per-Movie.png" style="max-width: 450px; width: 100%;"></p>
						<figcaption>Figure 2b: Graph showing how many samples have one, two or three genres</figcaption>
						<br>
					</figure>
				</div>
			</div>
			<div class="graph-arrows">
				<button class="arrow-button previous-button label-image" onclick="graphChanger(this)"><p>⮜ Previous</p></button>
				<button class="arrow-button next-button label-image" onclick="graphChanger(this)"><p>Next ⮞</p></button>
			</div>
			<p>As not all genres have enough representative samples, we initially decided to only keep the most common seven (although later extended to 12).
				After stripping the uncommon labels and dropping samples that no longer belonged to least one genre, we then evened up the label distributions through sampling.
				This is because an unbalanced label distribution can lead to bias when training a neural network.
			</p>

			<div>
				<figure class="centered" id="label-pie-raw">
					<div class="pie">
						<iframe src="Assets/Graphs/Label_Distribution_Raw.html" class="graph-html"></iframe>
					</div>
					<figcaption>Figure 3a: Pie chart of label distribution across all samples</figcaption>
					<br>
				</figure>
				<figure class="centered" id="label-pie-reduced" style="display: none;">
					<div class="pie">
						<iframe src="Assets/Graphs/Label_Distribution_Unbalanced.html" class="graph-html"></iframe>
					</div>
					<figcaption>Figure 3b: Pie chart of label distribution for samples belonging to top seven genres</figcaption>
					<br>
				</figure>
				<figure class="centered" id="label-pie-even" style="display: none;">
					<div class="pie">
						<iframe src="Assets/Graphs/Label_Distribution_Processed.html" class="graph-html"></iframe>
					</div>
					<figcaption>Figure 3c: Pie chart of evened out label distribution for top seven genres</figcaption>
					<br>
				</figure>
			</div>
			<div class="graph-arrows">
				<button class="arrow-button previous-button label-pie" onclick="graphChanger(this)"><p>⮜ Previous</p></button>
				<button class="arrow-button next-button label-pie" onclick="graphChanger(this)"><p>Next ⮞</p></button>
			</div>

			<br style="clear: both;">

			<p>We used various methods to inspect the movie description text including: finding words that are representative of each genre,
				locating common stop words (e.g. a, the, for) as well as words consistently used across all descriptions (e.g. young, man) that
				are common across all genres and discovering the most frequent bigrams and trigrams.
			</p>

			<div>
				<figure class="centered" id="scattertext-horror">
					<div class="graph scattertext">
						<iframe src="Assets/Graphs/Scattertext_Horror.html" class="graph-html"></iframe>
					</div>
					<figcaption>Figure 4a: Scattertext graph of word frequencies for horror film descriptions</figcaption>
					<br>
				</figure>
				<figure class="centered" id="scattertext-romance" style="display: none;">
					<div class="graph scattertext">
						<iframe src="Assets/Graphs/Scattertext_Romance.html" class="graph-html"></iframe>
					</div>
					<figcaption>Figure 4b: Scattertext graph of word frequencies for romance film descriptions</figcaption>
					<br>
				</figure>
				<div align="center">
					<figure class="centered" id="frequency-distribution" style="display: none;">
						<p><img src="Assets\Images\Frequency-Distribution.png" style="max-width: 650px; width: 100%;"></p>
						<figcaption>Figure 4c: Most common words across all film descriptions after stop word removal</figcaption>
						<br>
					</figure>
					<figure class="centered" id="bigrams" style="display: none;">
						<p><img src="Assets\Images\Bigrams.png" style="max-width: 800px; width: 100%;"></p>
						<figcaption>Figure 4d: Most common bigrams after stop word removal</figcaption>
						<br>
					</figure>
					<figure class="centered" id="trigrams" style="display: none;">
						<p><img src="Assets\Images\Trigrams.png" style="max-width: 800px; width: 100%;"></p>
						<figcaption>Figure 4e: Most common trigrams after stop word removal</figcaption>
						<br>
					</figure>
				</div>
			</div>
			<div class="graph-arrows">
				<button class="arrow-button previous-button desc-graphs" onclick="graphChanger(this)"><p>⮜ Previous</p></button>
				<button class="arrow-button next-button desc-graphs" onclick="graphChanger(this)"><p>Next ⮞</p></button>
			</div>
		</details>

		<br>

		<details>
			<summary class="h2">Label Encoding and Text Processing</summary>
			<p>Each film has between one and three genres allowing us to perform multi-label classification.
				Unlike multi-class, where only one output is given, multi-label allows multiple predictions to be made at once.
				Therefore to represent the multiple combinations of labels in a way that the classifier can understand, we used multi-hot encoding, i.e. a binary representation, where 1 signifies that a description belongs to a genre and 0 means that it does not.
			</p>
			<figure class="centered">
				<p><img class="multihot centered" src="Assets/Images/Multi-Hot.png"></p>
				<figcaption>Figure 5: Multi-hot label encoding of the genres</figcaption>
			</figure>

			<br>

			<p>Before a film description is given as input to the classifier, the text must first be converted to a canonical form.
				It is therefore processed in the following ways:</p>
			<ul>
				<li>The text is tokenised to separate the words within sentences</li>
				<li>Punctuation and bad characters are removed</li>
				<li>Accented characters are converted to non-accented form, for example “Léon” → “Leon”</li>
				<li>Stop words are removed with the NLTK stop word list</li>
				<li>Lemmatization is applied to convert words into a form compatible with GloVe word embeddings</li>
			</ul>

			<figure class="centered">
				<p><img class="descriptions-processed centered" src="Assets/Images/Description-Processing.png"></p>
				<figcaption>Figure 6: Processing the film descriptions before and after</figcaption>
			</figure>
		</details>

	</div>

	<br>

	<div>
		<a name="classifier" class="anchor"></a>
		<h1>Classifier</h1>
		<p>To select the best model architecture to deploy, we each focused on different architectures, across the group covering: CNN, LSTM, transformers, SVM and One-vs-Rest classifiers.
			We then decided upon the bidirectional LSTM because it had a reasonably good initial performance and unlike some of the other models it is compatible with GloVe word embeddings.
			Through optimization, we determined the best parameters for this model were: 120 hidden layers, 70% dropout, sigmoid activation function and a batch normalization layer.
		</p>
		<p>The model was then integrated into a pipeline to simplify the process of training a new model trained, saving its state and automatically deploying it to our web application.

		</p>
		<div>
			<figure class="centered" id="model-diagram">
				<p><img class="centered" id="lstm-diagram" src="Assets/Images/Model-Architecture.png"></p>
				<figcaption>Figure 7a: Classifier architecture diagram</figcaption>
				<br>
			</figure>
			<figure class="centered" id="model-matrix" style="display: none;">
				<p><img class="centered" src="Assets/Images/Confusion-Matrix.png" style="max-width: 700px; width: 100%;"></p>
				<figcaption>Figure 7b: Confusion matrices of a trained classifier with 40.1% test accuracy</figcaption>
				<br>
			</figure>
			<figure class="centered" id="model-pie" style="display: none;">
				<p><img class="centered" src="Assets/Images/Trained-Labels-Pie.png" style="max-width: 500px; width: 100%;"></p>
				<figcaption>Figure 7c: Pie chart of the best trained model's label distribution</figcaption>
				<br>
			</figure>
		</div>
		<div class="graph-arrows">
			<button class="arrow-button previous-button model-graphs" onclick="graphChanger(this)"><p>⮜ Previous</p></button>
			<button class="arrow-button next-button model-graphs" onclick="graphChanger(this)"><p>Next ⮞</p></button>
		</div>

		<br>

		<details>
			<summary class="h2">Pipeline Code</summary>
			<div class="notebook">
				<iframe src="Notebooks/IMDb-Genre-Predictor-Pipeline.html" class="notebook-html"></iframe>
			</div>
		</details>

	</div>

	<br>

	<div>
		<a name="topicmodelling" class="anchor"></a>
		<h1>Topic Modelling</h1>
		<p>As an alternative approach to our classification task, the team also experimented with the unsupervised topic modelling approaches Latent Dirichlet Allocation and Latent Semantic Analysis.
			Unfortunately, we found the topics (i.e. grouping of films) uncovered by these algorithms did not align with the film's genres and so they were not used when constructing our final classifier.
		</p>

		<br>

		<details>
			<summary class="h2">Latent Dirichlet Allocation (LDiA)</summary>
			<figure class="centered">
				<div class="graph">
					<iframe src="Assets/Graphs/Gensim_LDiA_7_Topics.html" class="graph-html"></iframe>
				</div>
				<figcaption>Figure 8a: Similarities and difference between topics, along with their most relevent terms</figcaption>
			</figure>
			<figure class="centered">
				<div class="graph">
					<iframe src="Assets/Graphs/tSNE_LDiA_7_Topics.html" class="graph-html"></iframe>
				</div>
				<figcaption>Figure 8a: Similarities and difference between topics, along with their most relevent terms</figcaption>
			</figure>

			<p>In </p>

			<p><img src="Assets/Images/LDiA_Coherence.png" class="coherence-graph centered"></p>

			<div class="graph">
				<iframe src="Assets/Graphs/tSNE_LDiA_47_Topics.html" class="graph-html"></iframe>
			</div>
		</details>

		<br>

		<details>
			<summary class="h2">Latent Semantic Analysis (LSA)</summary>
			<p>Si</p>

			<div class="graph">
				<iframe src="Assets/Graphs/tSNE_LSA_7_Topics.html" class="graph-html"></iframe>
			</div>

			<p><img src="Assets/Images/LSA_Coherence.png" class="coherence-graph centered"></p>

			<div class="graph">
				<iframe src="Assets/Graphs/tSNE_LSA_2_Topics.html" class="graph-html"></iframe>
			</div>
		</details>

		<br>

		<details>
			<summary class="h2">Topic Modelling Code</summary>
			<div class="notebook">
				<iframe src="Notebooks/LDiA-and-LSA-Topic-Modelling.html" class="notebook-html"></iframe>
			</div>
		</details>

	</div>

	<br>

	<div>
		<a name="code" class="anchor"></a>
		<h1>Running the Code</h1>
		<p>The full code has been uploaded to <a href="https://github.com/TomMakesThings/Movie-Genre-Predictor" target="_blank">GitHub</a>.
			To download the repository, <a href="https://github.com/TomMakesThings/Movie-Genre-Predictor/archive/refs/heads/main.zip">click here.</a>
		</p>
		<p>To ensure all team members could execute the code during development, it was created using a <a href="https://www.anaconda.com/products/individual" target="_blank">conda environment</a>.
			This environment has been saved as a YAML file, environment.yml, and is included in the repository.
			To recreate this environment, open the Anaconda prompt and enter the command below, where environment.yml is the file path of the enviroment file.
		</p>
		<p><a class="code">conda env create -f environment.yml</a></p>

		<br>

		<h2>Web application</h2>
		<p>To run the classifier web application:</p>
		<ol>
			<li><a class="code">conda activate MoviePredictor</a></li>
			<li>Navigate to <a class="code">Web_App/flaskr</a></li>
			<li>Run command <a class="code">python main.py</a></li>
		</ol>

		<br>

		<video controls>
			<source src="Assets/Videos/Site-Launch.mov" type="video/mp4">
				Your browser does not support the video tag.
		</video>

		<br>

		<h2>Jupyter notebooks</h2>

	</div>

	<br>

	<div>
		<a name="contributions" class="anchor"></a>
		<h1>Contributions</h1>
		<h2>Tom</h2>
		<ul>
			<li>CI/CD pipeline development</li>
			<li>Model training, testing and optimization</li>
			<li>Hosting the selected model on the backend of the web application</li>
			<li>Creation of this site</li>
		</ul>
		<h2>Roger</h2>
		<ul>
			<li>Backend development of the Flask web application</li>
			<li>Hosting the app prototype on Heroku</li>
			<li>Functional testing of the application</li>
		</ul>
		<h2>Lavinia</h2>
		<ul>
			<li>Research of web service hosting options</li>
			<li>Frontend development of the web application</li>
			<li>Creation of video demonstrations</li>
		</ul>
	</div>

	<br>

</div>

<br>

<div class="footer">
	<div class="footer-center">
		<a href="https://github.com/TomMakesThings"><b>&copy; TomMakesThings <script>document.write(new Date().getUTCFullYear());</script></b></a>
	</div>
</div>

<script src="Javascript/graph_changer.js"></script>
<script src="Javascript/navbar.js"></script>

</body>
</html>
